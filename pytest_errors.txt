============================= test session starts =============================
platform win32 -- Python 3.12.7, pytest-7.4.3, pluggy-1.6.0
rootdir: C:\Users\theha\Documents\GIT\FantasyF1\FantasyF1_BE
configfile: pyproject.toml
plugins: anyio-3.7.1, Flask-Dance-7.1.0, asyncio-0.21.1, cov-4.1.0
asyncio: mode=Mode.AUTO
collected 12 items

tests\test_auth_endpoints.py EEEEEEEEEEEE                                [100%]

=================================== ERRORS ====================================
___________________ ERROR at setup of test_register_success ___________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
_____________ ERROR at setup of test_register_duplicate_username ______________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
________________ ERROR at setup of test_register_weak_password ________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
____________________ ERROR at setup of test_login_success _____________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
_________________ ERROR at setup of test_login_wrong_password _________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
________________ ERROR at setup of test_login_nonexistent_user ________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
________________ ERROR at setup of test_refresh_token_success _________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
________________ ERROR at setup of test_refresh_token_invalid _________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
_______________ ERROR at setup of test_get_current_user_profile _______________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
________ ERROR at setup of test_get_current_user_profile_unauthorized _________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
_____________ ERROR at setup of test_update_current_user_profile ______________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
_________________ ERROR at setup of test_update_user_password _________________

event_loop = <ProactorEventLoop running=False closed=False debug=False>
request = <SubRequest '_setup_database' for <Function test_register_success>>
kwargs = {}
setup = <function _wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup at 0x00000177357A04A0>

    @functools.wraps(fixture)
    def _async_fixture_wrapper(
        event_loop: asyncio.AbstractEventLoop, request: SubRequest, **kwargs: Any
    ):
        func = _perhaps_rebind_fixture_func(
            fixture, request.instance, fixturedef.unittest
        )
    
        async def setup():
            res = await func(**_add_kwargs(func, kwargs, event_loop, request))
            return res
    
>       return event_loop.run_until_complete(setup())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <ProactorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_async_fixture.<locals>._async_fixture_wrapper.<locals>.setup() done, defined ...ytest_asyncio\plugin.py:322> exception=InvalidPasswordError('password authentication failed for user "fantasyf1_dev"')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def setup():
>       res = await func(**_add_kwargs(func, kwargs, event_loop, request))

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pytest_asyncio\plugin.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

event_loop = <ProactorEventLoop running=False closed=False debug=False>

    @pytest.fixture(scope="session", autouse=True)
    async def _setup_database(event_loop):
        """Create database tables for testing"""
        from app.db.base import Base
    
        # Import all models to ensure they're registered with Base
        from app.models import constructor, driver, league, race, user  # noqa: F401
    
        # Create all tables using async connection
        # Use connect() instead of begin() to avoid transaction isolation
>       async with engine.connect() as conn:

tests\conftest.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\base.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x0000017735785FE0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\ext\asyncio\engine.py:270: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
                    value = await result
                except BaseException:
                    # this allows an exception to be raised within
                    # the moderated greenlet so that it can continue
                    # its expected flow.
>                   result = context.throw(*sys.exc_info())

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x00000177357476E0>
engine = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\base.py:3293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:1269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x000001773570CC10>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\impl.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:393: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x0000017733AE2120>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:678: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x00000177356C0CD0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\langhelpers.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\pool\base.py:898: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x000001773552E4B0>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\create.py:645: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x00000177335ABD10>
cargs = ()
cparams = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}

    def connect(self, *cargs, **cparams):
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\engine\default.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x000001773368BFE0>
arg = ()
kw = {'database': 'fantasyf1_dev', 'host': 'localhost', 'password': 'dev_password_123', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x0000017733B1E0C0>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\dialects\postgresql\asyncpg.py:941: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = <coroutine object connect at 0x000001773572EB60>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not isinstance(current, _AsyncIoGreenlet):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.driver.switch(awaitable)  # type: ignore[no-any-return]

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://fantasyf1_dev:***@localhost:5432/fantasyf1_dev)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x00000177355C6740 (otid=0x0000017731BB76F0) dead>
switch_occurred = True
result = <coroutine object connect at 0x000001773572EB60>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        try:
            result = context.switch(*args, **kwargs)
            while not context.dead:
                switch_occurred = True
                try:
                    # wait for a coroutine from await_only and then return its
                    # result back to it.
>                   value = await result

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\sqlalchemy\util\_concurrency_py3k.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=False,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.get_event_loop().run_until_complete(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs
            )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connection.py:2329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

loop = <ProactorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'fantasyf1_dev', 'direct_tls': False, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:828: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

params = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)
retry = True, addr = ('localhost', 5432)
loop = <ProactorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='fantasyf1_dev', password='dev_password_123', database='fantasyf1_dev', ssl=<ssl.SSLContext ...slmode=<SSLMode.prefer: 2>, direct_tls=False, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>)

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.direct_tls:
            # if ssl and direct_tls are given, skip STARTTLS and perform direct
            # SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
        tr, pr = await connector
    
        try:
>           await connected
E           asyncpg.exceptions.InvalidPasswordError: password authentication failed for user "fantasyf1_dev"

..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\asyncpg\connect_utils.py:876: InvalidPasswordError
============================== warnings summary ===============================
..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\_internal\_config.py:271
..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\_internal\_config.py:271
..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\_internal\_config.py:271
..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\_internal\_config.py:271
  C:\Users\theha\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\_internal\_config.py:271: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/
    warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR tests/test_auth_endpoints.py::test_register_success - asyncpg.exception...
ERROR tests/test_auth_endpoints.py::test_register_duplicate_username - asyncp...
ERROR tests/test_auth_endpoints.py::test_register_weak_password - asyncpg.exc...
ERROR tests/test_auth_endpoints.py::test_login_success - asyncpg.exceptions.I...
ERROR tests/test_auth_endpoints.py::test_login_wrong_password - asyncpg.excep...
ERROR tests/test_auth_endpoints.py::test_login_nonexistent_user - asyncpg.exc...
ERROR tests/test_auth_endpoints.py::test_refresh_token_success - asyncpg.exce...
ERROR tests/test_auth_endpoints.py::test_refresh_token_invalid - asyncpg.exce...
ERROR tests/test_auth_endpoints.py::test_get_current_user_profile - asyncpg.e...
ERROR tests/test_auth_endpoints.py::test_get_current_user_profile_unauthorized
ERROR tests/test_auth_endpoints.py::test_update_current_user_profile - asyncp...
ERROR tests/test_auth_endpoints.py::test_update_user_password - asyncpg.excep...
======================= 4 warnings, 12 errors in 2.28s ========================
